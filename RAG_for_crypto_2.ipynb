{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Cj8BsXDCOB5u",
        "outputId": "ef70f934-6b16-4168-e4dd-7d510287c4fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.49)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.21)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.19)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (0.3.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (2.11.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (4.13.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (0.4.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.20 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lMC0GQteNsYT",
        "outputId": "7d29b3fe-9793-43d2-9217-cac428500a1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.21)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.12-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.69.0)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.49)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.19)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.23.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.2)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.16)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4) (4.13.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.31.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.31.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.52b1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
            "Collecting opentelemetry-util-http==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.52b1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.29.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (2.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading langchain_openai-0.3.12-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.31.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.31.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.31.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.52b1-py3-none-any.whl (31 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.52b1-py3-none-any.whl (7.3 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.23.0-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53800 sha256=6f338e463f55ad63bbe73e40552840d43bfc547335b81a4fc441fcb1f3f79e63\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, pyproject_hooks, overrides, opentelemetry-util-http, opentelemetry-proto, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, tiktoken, starlette, posthog, opentelemetry-exporter-otlp-proto-common, coloredlogs, build, bs4, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langchain_openai, opentelemetry-instrumentation-fastapi, chromadb\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 bs4-0.0.2 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.6.3 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.12 httptools-0.6.4 humanfriendly-10.0 kubernetes-32.0.1 langchain_openai-0.3.12 mmh3-5.1.0 monotonic-1.6 onnxruntime-1.21.0 opentelemetry-exporter-otlp-proto-common-1.31.1 opentelemetry-exporter-otlp-proto-grpc-1.31.1 opentelemetry-instrumentation-0.52b1 opentelemetry-instrumentation-asgi-0.52b1 opentelemetry-instrumentation-fastapi-0.52b1 opentelemetry-proto-1.31.1 opentelemetry-util-http-0.52b1 overrides-7.7.0 posthog-3.23.0 pypika-0.48.9 pyproject_hooks-1.2.0 starlette-0.46.1 tiktoken-0.9.0 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install langchain langchain_openai openai tiktoken chromadb pandas nltk bs4 requests python-dotenv\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from dotenv import load_dotenv\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# LangChain and OpenAI imports\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.schema import Document\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "# Download NLTK resources for text preprocessing\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load environment variables (API keys)\n",
        "load_dotenv()\n",
        "\n",
        "# Set OpenAI API key  #MY_new_OPENAI_key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Data Collection\n",
        "\n",
        "def scrape_crypto_articles(num_articles=10):\n",
        "    \"\"\"\n",
        "    Scrape cryptocurrency news articles from a sample source.\n",
        "    In a production system, you'd use more reliable sources with proper API access.\n",
        "    \"\"\"\n",
        "    print(\"Fetching cryptocurrency articles...\")\n",
        "\n",
        "\n",
        "\n",
        "    sample_articles = [\n",
        "        {\n",
        "            \"title\": \"Bitcoin Hits New All-Time High Amid Institutional Adoption\",\n",
        "            \"content\": \"Bitcoin has reached a new all-time high as institutional investors continue to adopt the cryptocurrency. Major corporations have added Bitcoin to their balance sheets, viewing it as a hedge against inflation. The cryptocurrency has shown significant volatility in the past, but has demonstrated strong recovery patterns. Analysts suggest this trend could continue as mainstream adoption increases.\",\n",
        "            \"date\": \"2025-03-15\",\n",
        "            \"source\": \"CryptoNews\",\n",
        "            \"url\": \"https://example.com/bitcoin-ath\",\n",
        "            \"tickers\": [\"BTC\"]\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Ethereum's Shift to Proof-of-Stake Reduces Energy Consumption by 99%\",\n",
        "            \"content\": \"Ethereum has successfully completed its transition to a Proof-of-Stake consensus mechanism, reducing its energy consumption by approximately 99%. This eco-friendly shift has attracted more environmentally conscious investors. The upgrade also introduces enhanced scalability features and reduced gas fees for transactions, making the network more accessible for smaller investors and developers. These improvements could position Ethereum for long-term growth in the smart contract platform market.\",\n",
        "            \"date\": \"2025-03-10\",\n",
        "            \"source\": \"BlockchainInsider\",\n",
        "            \"url\": \"https://example.com/ethereum-pos\",\n",
        "            \"tickers\": [\"ETH\"]\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Cardano Launches New DeFi Platform, ADA Price Surges\",\n",
        "            \"content\": \"Cardano has launched a new decentralized finance platform, causing its native token ADA to surge in price. The platform aims to provide financial services to unbanked populations. Cardano's methodical, research-driven approach to development has been criticized for slow progress but praised for security and reliability. Its focus on academic rigor and formal verification methods makes it attractive for risk-averse investors looking for sustainable growth rather than quick gains.\",\n",
        "            \"date\": \"2025-03-12\",\n",
        "            \"source\": \"DeFiDaily\",\n",
        "            \"url\": \"https://example.com/cardano-defi\",\n",
        "            \"tickers\": [\"ADA\"]\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Solana Network Experiences Growth in NFT Market Share\",\n",
        "            \"content\": \"Solana's blockchain has been gaining significant traction in the NFT marketplace, challenging Ethereum's dominance. The network's high throughput and low transaction fees have made it attractive to NFT creators and collectors. Despite past network outages affecting confidence, recent protocol upgrades have improved stability. Solana's ecosystem continues to expand with new projects and applications, potentially offering high growth opportunities alongside higher technical risks.\",\n",
        "            \"date\": \"2025-03-16\",\n",
        "            \"source\": \"NFTWorld\",\n",
        "            \"url\": \"https://example.com/solana-nfts\",\n",
        "            \"tickers\": [\"SOL\"]\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Ripple Wins Regulatory Clarity in Major Markets\",\n",
        "            \"content\": \"Ripple has secured regulatory clarity in several major markets, boosting confidence in XRP. The company continues to expand its cross-border payment solutions with financial institutions globally. Regulatory developments have had significant impact on XRP's price volatility. Despite legal challenges in some jurisdictions, Ripple's underlying technology for international transfers remains compelling for financial institutions seeking efficiency improvements.\",\n",
        "            \"date\": \"2025-03-05\",\n",
        "            \"source\": \"CryptoRegulation\",\n",
        "            \"url\": \"https://example.com/ripple-regulations\",\n",
        "            \"tickers\": [\"XRP\"]\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Binance Coin Grows as Exchange Expands Services\",\n",
        "            \"content\": \"Binance Coin (BNB) has seen steady growth as the Binance exchange continues to expand its service offerings. The token's utility within the Binance ecosystem provides it with practical use cases beyond speculation. Binance's regular token burns reduce supply, potentially supporting price appreciation. However, regulatory scrutiny of centralized exchanges presents ongoing compliance challenges and risks for the associated token.\",\n",
        "            \"date\": \"2025-03-20\",\n",
        "            \"source\": \"ExchangeNews\",\n",
        "            \"url\": \"https://example.com/bnb-growth\",\n",
        "            \"tickers\": [\"BNB\"]\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Polkadot Parachains Show Promise for Interoperability Solutions\",\n",
        "            \"content\": \"Polkadot's parachain ecosystem is demonstrating promising results for blockchain interoperability. The network's ability to connect different blockchains could solve major fragmentation issues in the crypto space. Polkadot's unique architecture allows specialized blockchains to operate with shared security, creating opportunities for niche applications with cross-chain capabilities. This technical approach could provide significant long-term value if wider blockchain adoption continues across industries.\",\n",
        "            \"date\": \"2025-03-08\",\n",
        "            \"source\": \"InteropTech\",\n",
        "            \"url\": \"https://example.com/polkadot-parachains\",\n",
        "            \"tickers\": [\"DOT\"]\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Algorand Partners with Central Banks for CBDC Development\",\n",
        "            \"content\": \"Algorand has announced partnerships with multiple central banks for central bank digital currency (CBDC) development projects. These high-profile collaborations highlight the platform's institutional-grade capabilities. Algorand's pure proof-of-stake protocol offers deterministic finality and carbon-negative operations, making it suitable for regulated financial applications. Such partnerships could establish Algorand as a key player in the institutional blockchain space, though retail adoption remains more limited than some competitors.\",\n",
        "            \"date\": \"2025-03-18\",\n",
        "            \"source\": \"CBDCInsights\",\n",
        "            \"url\": \"https://example.com/algorand-cbdc\",\n",
        "            \"tickers\": [\"ALGO\"]\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Chainlink Expands Data Oracle Services Beyond Crypto\",\n",
        "            \"content\": \"Chainlink has expanded its oracle services beyond the cryptocurrency sector, now providing data feeds to traditional financial markets. This broadening use case strengthens Chainlink's position as the leading decentralized oracle network. The project's focus on reliable data provision has made it essential infrastructure for many DeFi applications. As more industries require tamper-proof data for smart contracts, Chainlink's utility and potential market continue to grow, offering a unique investment profile tied to the broader blockchain ecosystem rather than any single platform.\",\n",
        "            \"date\": \"2025-03-14\",\n",
        "            \"source\": \"DeFiInsider\",\n",
        "            \"url\": \"https://example.com/chainlink-expansion\",\n",
        "            \"tickers\": [\"LINK\"]\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Avalanche Subnet Technology Enables Custom Blockchain Deployment\",\n",
        "            \"content\": \"Avalanche's subnet technology is enabling enterprises to deploy custom blockchains tailored to specific requirements. This flexibility has attracted projects from gaming to finance seeking scalable blockchain solutions. Avalanche's architecture balances decentralization with high performance, processing thousands of transactions per second with sub-second finality. The platform's ability to host application-specific blockchains positions it as a versatile foundation for next-generation Web3 services, potentially capturing market share across multiple verticals simultaneously.\",\n",
        "            \"date\": \"2025-03-09\",\n",
        "            \"source\": \"EnterpriseChain\",\n",
        "            \"url\": \"https://example.com/avalanche-subnets\",\n",
        "            \"tickers\": [\"AVAX\"]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Create a DataFrame for easier manipulation\n",
        "    df = pd.DataFrame(sample_articles)\n",
        "    print(f\"Collected {len(df)} articles\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "DlThSaiINt3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Option 1: Using News APIs\n"
      ],
      "metadata": {
        "id": "XuqaMDL8l-Fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4 feedparser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_qTOZRzmmow",
        "outputId": "0a829dfb-cedc-47ee-a68c-fe414b25acc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.0)\n",
            "Collecting sgmllib3k (from feedparser)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=9caf123eb75539ed504b108a0858165aafd7a0c82a49bac9bd24f3f8a61c45c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, feedparser\n",
            "Successfully installed feedparser-6.0.11 sgmllib3k-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_crypto_articles_api(num_articles=10):\n",
        "    \"\"\"Fetch cryptocurrency news using a news API\"\"\"\n",
        "    import requests\n",
        "    import os\n",
        "    from datetime import datetime, timedelta\n",
        "\n",
        "    # Option 1: NewsAPI.org\n",
        "    # Sign up at https://newsapi.org for an API key (free tier available)\n",
        "    api_key = os.getenv(\"NEWS_API_KEY\", \"\")\n",
        "\n",
        "    # Set parameters\n",
        "    days_back = 7\n",
        "    from_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')\n",
        "\n",
        "    url = \"https://newsapi.org/v2/everything\"\n",
        "    params = {\n",
        "        \"q\": \"cryptocurrency OR bitcoin OR ethereum OR blockchain\",\n",
        "        \"language\": \"en\",\n",
        "        \"sortBy\": \"publishedAt\",\n",
        "        \"from\": from_date,\n",
        "        \"apiKey\": api_key,\n",
        "        \"pageSize\": num_articles\n",
        "    }\n",
        "\n",
        "    print(f\"Fetching cryptocurrency news from the past {days_back} days...\")\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, params=params)\n",
        "        data = response.json()\n",
        "\n",
        "        if response.status_code == 200 and data.get(\"status\") == \"ok\":\n",
        "            articles = []\n",
        "\n",
        "            for article in data.get(\"articles\", []):\n",
        "                # Extract cryptocurrency tickers mentioned in the title/description\n",
        "                content = (article.get(\"title\", \"\") + \" \" + article.get(\"description\", \"\")).lower()\n",
        "                tickers = []\n",
        "                for ticker in [\"BTC\", \"ETH\", \"ADA\", \"SOL\", \"XRP\", \"BNB\", \"DOT\", \"AVAX\", \"LINK\", \"ALGO\"]:\n",
        "                    if ticker.lower() in content or ticker in content:\n",
        "                        tickers.append(ticker)\n",
        "\n",
        "                # Default to general crypto if no specific ticker found\n",
        "                if not tickers:\n",
        "                    tickers = [\"CRYPTO\"]\n",
        "\n",
        "                articles.append({\n",
        "                    \"title\": article.get(\"title\", \"\"),\n",
        "                    \"content\": article.get(\"description\", \"\") + \" \" + article.get(\"content\", \"\"),\n",
        "                    \"date\": article.get(\"publishedAt\", \"\")[:10],\n",
        "                    \"source\": article.get(\"source\", {}).get(\"name\", \"\"),\n",
        "                    \"url\": article.get(\"url\", \"\"),\n",
        "                    \"tickers\": tickers\n",
        "                })\n",
        "\n",
        "            # Create DataFrame\n",
        "            df = pd.DataFrame(articles)\n",
        "            print(f\"Collected {len(df)} articles from News API\")\n",
        "            return df\n",
        "        else:\n",
        "            print(f\"Error fetching news: {data.get('message', 'Unknown error')}\")\n",
        "            # Fall back to sample data\n",
        "            return scrape_crypto_articles(num_articles)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Exception when fetching news: {e}\")\n",
        "        # Fall back to sample data\n",
        "        return scrape_crypto_articles(num_articles)"
      ],
      "metadata": {
        "id": "HBqcD_VdmBnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Option 2: Direct Web Scraping"
      ],
      "metadata": {
        "id": "sNmyJv95ok7t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mUXJgYyiolYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Document Processing\n",
        "\n",
        "def process_articles_to_documents(articles_df):\n",
        "    \"\"\"Convert articles DataFrame into LangChain Document objects.\"\"\"\n",
        "    documents = []\n",
        "\n",
        "    for _, row in articles_df.iterrows():\n",
        "        # Create metadata for better retrieval context\n",
        "        metadata = {\n",
        "            \"title\": row[\"title\"],\n",
        "            \"date\": row[\"date\"],\n",
        "            \"source\": row[\"source\"],\n",
        "            \"url\": row[\"url\"],\n",
        "            \"tickers\": \",\".join(row[\"tickers\"])\n",
        "        }\n",
        "\n",
        "        # Create Document object with content and metadata\n",
        "        doc = Document(\n",
        "            page_content=f\"Title: {row['title']}\\n\\nContent: {row['content']}\",\n",
        "            metadata=metadata\n",
        "        )\n",
        "        documents.append(doc)\n",
        "\n",
        "    print(f\"Processed {len(documents)} documents with metadata\")\n",
        "    return documents\n",
        "\n",
        "# Function to split documents into chunks for embedding\n",
        "def split_documents(documents):\n",
        "    \"\"\"Split documents into smaller chunks for better retrieval.\"\"\"\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=500,\n",
        "        chunk_overlap=50,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
        "    )\n",
        "\n",
        "    chunks = text_splitter.split_documents(documents)\n",
        "    print(f\"Split documents into {len(chunks)} chunks\")\n",
        "    return chunks\n"
      ],
      "metadata": {
        "id": "ANZcXqxTPwE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Vector Store Creation\n",
        "\n",
        "def create_vector_store(chunks):\n",
        "    \"\"\"Create a vector store from document chunks using OpenAI embeddings.\"\"\"\n",
        "    # Initialize OpenAI embeddings\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "\n",
        "    # Create vector store - using Chroma for in-memory storage\n",
        "    # In production, you might want to use Supabase, Pinecone, or another persistent vector store\n",
        "    vector_store = Chroma.from_documents(\n",
        "        documents=chunks,\n",
        "        embedding=embeddings\n",
        "    )\n",
        "\n",
        "    print(\"Vector store created successfully\")\n",
        "    return vector_store"
      ],
      "metadata": {
        "id": "tXO1usG3P5_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. User Profile Processing\n",
        "\n",
        "def generate_search_queries(risk_profile):\n",
        "    \"\"\"\n",
        "    Generate appropriate search queries based on user's risk profile.\n",
        "    Different risk tolerance levels will prioritize different aspects of cryptocurrencies.\n",
        "    \"\"\"\n",
        "    queries = []\n",
        "\n",
        "    if risk_profile.lower() == \"conservative\" or risk_profile.lower() == \"low\":\n",
        "        queries = [\n",
        "            \"stable cryptocurrency with low volatility\",\n",
        "            \"established cryptocurrency with institutional adoption\",\n",
        "            \"cryptocurrency with strong regulatory compliance\",\n",
        "            \"blue-chip cryptocurrency long-term investment\"\n",
        "        ]\n",
        "    elif risk_profile.lower() == \"moderate\" or risk_profile.lower() == \"medium\":\n",
        "        queries = [\n",
        "            \"balanced risk-reward cryptocurrency\",\n",
        "            \"cryptocurrency with growing adoption\",\n",
        "            \"established altcoins with utility\",\n",
        "            \"mid-cap cryptocurrency with potential\"\n",
        "        ]\n",
        "    elif risk_profile.lower() == \"aggressive\" or risk_profile.lower() == \"high\":\n",
        "        queries = [\n",
        "            \"high potential growth cryptocurrency\",\n",
        "            \"emerging cryptocurrency projects\",\n",
        "            \"innovative blockchain technology\",\n",
        "            \"new cryptocurrency with unique features\"\n",
        "        ]\n",
        "    else:\n",
        "        # Default to a mix of queries\n",
        "        queries = [\n",
        "            \"reliable cryptocurrency investment\",\n",
        "            \"cryptocurrency market trends\",\n",
        "            \"promising cryptocurrency projects\",\n",
        "            \"cryptocurrency adoption and growth\"\n",
        "        ]\n",
        "\n",
        "    print(f\"Generated {len(queries)} search queries for {risk_profile} risk profile\")\n",
        "    return queries\n"
      ],
      "metadata": {
        "id": "ig_xa0HmQC9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Retrieval System\n",
        "\n",
        "def retrieve_relevant_chunks(vector_store, queries, top_k=3):\n",
        "    \"\"\"\n",
        "    Retrieve relevant document chunks based on generated queries.\n",
        "    Combines results from multiple queries for better coverage.\n",
        "    \"\"\"\n",
        "    all_docs = []\n",
        "\n",
        "    for query in queries:\n",
        "        docs = vector_store.similarity_search(query, k=top_k)\n",
        "        all_docs.extend(docs)\n",
        "\n",
        "    # Remove duplicates while preserving order\n",
        "    unique_docs = []\n",
        "    seen_content = set()\n",
        "\n",
        "    for doc in all_docs:\n",
        "        content = doc.page_content\n",
        "        if content not in seen_content:\n",
        "            seen_content.add(content)\n",
        "            unique_docs.append(doc)\n",
        "\n",
        "    print(f\"Retrieved {len(unique_docs)} unique relevant chunks\")\n",
        "    return unique_docs\n"
      ],
      "metadata": {
        "id": "Mx3VFhWtQM7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. LLM Response Generation\n",
        "\n",
        "def create_rag_chain(risk_profile):\n",
        "    \"\"\"Create a RAG chain that combines retrieval with LLM generation.\"\"\"\n",
        "\n",
        "    # Initialize LLM\n",
        "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.2)\n",
        "\n",
        "    # Create the prompt template\n",
        "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "    You are a cryptocurrency investment advisor specializing in providing personalized advice based on current market information.\n",
        "\n",
        "    User Risk Profile: {risk_profile}\n",
        "    Current Date: {current_date}\n",
        "\n",
        "    Based on the following recent cryptocurrency articles and information, provide investment recommendations tailored to the user's risk profile:\n",
        "\n",
        "    {context}\n",
        "\n",
        "    Instructions:\n",
        "    1. Analyze the provided information and identify cryptocurrencies that match the user's {risk_profile} risk profile.\n",
        "    2. Provide 2-4 specific cryptocurrency recommendations with clear reasoning.\n",
        "    3. For each recommendation, include:\n",
        "       - Name and ticker symbol\n",
        "       - Why it fits the user's risk profile\n",
        "       - Key strengths and potential risks\n",
        "       - Suggested allocation percentage (approximate)\n",
        "    4. Add a brief market overview based on the recent articles.\n",
        "    5. Include appropriate disclaimers about cryptocurrency investments.\n",
        "\n",
        "    Your recommendations should be balanced, evidence-based, and clearly connected to the user's risk tolerance.\n",
        "    \"\"\")\n",
        "\n",
        "    # Create the RAG chain\n",
        "    chain = (\n",
        "        {\"context\": lambda x: x, \"risk_profile\": lambda _: risk_profile, \"current_date\": lambda _: datetime.now().strftime(\"%Y-%m-%d\")}\n",
        "        | prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    return chain"
      ],
      "metadata": {
        "id": "8LeBHFOUQRNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Main RAG System Function\n",
        "# ---------------------------\n",
        "\n",
        "def crypto_advisor_rag(risk_profile):\n",
        "    \"\"\"\n",
        "    Main function that orchestrates the RAG system workflow.\n",
        "    1. Collects and processes cryptocurrency articles\n",
        "    2. Creates vector store\n",
        "    3. Generates queries based on user risk profile\n",
        "    4. Retrieves relevant information\n",
        "    5. Generates personalized investment advice\n",
        "    \"\"\"\n",
        "    print(f\"Starting cryptocurrency advisor for {risk_profile} risk profile...\")\n",
        "\n",
        "    # Step 1: Collect articles\n",
        "    articles_df = scrape_crypto_articles_api()\n",
        "\n",
        "    # Step 2: Process articles into documents\n",
        "    documents = process_articles_to_documents(articles_df)\n",
        "\n",
        "    # Step 3: Split documents into chunks\n",
        "    chunks = split_documents(documents)\n",
        "\n",
        "    # Step 4: Create vector store\n",
        "    vector_store = create_vector_store(chunks)\n",
        "\n",
        "    # Step 5: Generate search queries based on risk profile\n",
        "    queries = generate_search_queries(risk_profile)\n",
        "\n",
        "    # Step 6: Retrieve relevant chunks\n",
        "    relevant_chunks = retrieve_relevant_chunks(vector_store, queries)\n",
        "\n",
        "    # Step 7: Create and run RAG chain\n",
        "    rag_chain = create_rag_chain(risk_profile)\n",
        "    response = rag_chain.invoke(relevant_chunks)\n",
        "\n",
        "    print(\"Investment advice generated successfully!\")\n",
        "    return response\n"
      ],
      "metadata": {
        "id": "MiuVu-gUQcvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. User Interface Function\n",
        "# --------------------------\n",
        "\n",
        "def get_investment_advice():\n",
        "    \"\"\"\n",
        "    Simple function to collect user input and display results.\n",
        "    In a real application, this would be a web or mobile interface.\n",
        "    \"\"\"\n",
        "    print(\"Welcome to the Cryptocurrency Investment Advisor!\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Get user's risk profile\n",
        "    print(\"\\nPlease specify your risk tolerance:\")\n",
        "    print(\"1: Conservative (Low risk)\")\n",
        "    print(\"2: Moderate (Medium risk)\")\n",
        "    print(\"3: Aggressive (High risk)\")\n",
        "\n",
        "    risk_choice = input(\"\\nEnter your choice (1-3): \")\n",
        "\n",
        "    risk_profile_map = {\n",
        "        \"1\": \"Conservative\",\n",
        "        \"2\": \"Moderate\",\n",
        "        \"3\": \"Aggressive\"\n",
        "    }\n",
        "\n",
        "    risk_profile = risk_profile_map.get(risk_choice, \"Moderate\")\n",
        "\n",
        "    print(f\"\\nGenerating investment advice for {risk_profile} risk profile...\")\n",
        "    print(\"This may take a moment while we analyze the latest cryptocurrency information.\")\n",
        "\n",
        "    # Get investment advice\n",
        "    advice = crypto_advisor_rag(risk_profile)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"Your Personalized Cryptocurrency Investment Advice:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(advice)\n"
      ],
      "metadata": {
        "id": "5fa-z79_Qhes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_advice = crypto_advisor_rag(\"Moderate\")\n",
        "print(\"\\nSample Investment Advice for Moderate Risk Profile:\")\n",
        "print(\"=\" * 60)\n",
        "print(sample_advice)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL83TlyXQm0V",
        "outputId": "de81065a-d702-4f5f-df1c-8f60681bebfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting cryptocurrency advisor for Moderate risk profile...\n",
            "Fetching cryptocurrency news from the past 7 days...\n",
            "Exception when fetching news: can only concatenate str (not \"NoneType\") to str\n",
            "Fetching cryptocurrency articles...\n",
            "Collected 10 articles\n",
            "Processed 10 documents with metadata\n",
            "Split documents into 23 chunks\n",
            "Vector store created successfully\n",
            "Generated 4 search queries for Moderate risk profile\n",
            "Retrieved 7 unique relevant chunks\n",
            "Investment advice generated successfully!\n",
            "\n",
            "Sample Investment Advice for Moderate Risk Profile:\n",
            "============================================================\n",
            "### Market Overview:\n",
            "Based on recent articles, the cryptocurrency market is experiencing significant developments in terms of institutional adoption, interoperability solutions, and partnerships with central banks. Bitcoin (BTC) has reached new all-time highs driven by institutional interest, while projects like Polkadot (DOT), Algorand (ALGO), and Chainlink (LINK) are making strides in their respective niches within the blockchain ecosystem.\n",
            "\n",
            "### Cryptocurrency Recommendations:\n",
            "\n",
            "1. **Algorand (ALGO)**\n",
            "   - **Why it fits the user's risk profile:** Algorand's partnerships with central banks for CBDC development projects showcase its institutional-grade capabilities, making it a relatively stable investment option.\n",
            "   - **Key strengths:** Pure proof-of-stake protocol, deterministic finality, carbon-negative operations, and potential for regulated financial applications.\n",
            "   - **Potential risks:** Limited retail adoption compared to some competitors.\n",
            "   - **Suggested allocation percentage:** 25%\n",
            "\n",
            "2. **Chainlink (LINK)**\n",
            "   - **Why it fits the user's risk profile:** Chainlink's expansion beyond crypto into providing data oracle services for smart contracts offers a unique investment profile tied to the broader blockchain ecosystem.\n",
            "   - **Key strengths:** Growing utility in tamper-proof data provision, potential market expansion, and relevance to various industries.\n",
            "   - **Potential risks:** Dependency on the adoption of smart contracts and decentralized applications.\n",
            "   - **Suggested allocation percentage:** 20%\n",
            "\n",
            "3. **Polkadot (DOT)**\n",
            "   - **Why it fits the user's risk profile:** Polkadot's focus on interoperability solutions positions it well for long-term value if blockchain adoption continues across industries.\n",
            "   - **Key strengths:** Parachains for scalability, interoperability, and potential for broader blockchain adoption.\n",
            "   - **Potential risks:** Competition from other interoperability projects and the need for sustained industry adoption.\n",
            "   - **Suggested allocation percentage:** 20%\n",
            "\n",
            "### Disclaimer:\n",
            "Cryptocurrency investments are highly volatile and speculative in nature. The market can experience rapid fluctuations, and investors should conduct thorough research and consider their risk tolerance before making any investment decisions. Diversification and careful portfolio management are essential in managing risk in the cryptocurrency space.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x-FnrY-TnD7z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}